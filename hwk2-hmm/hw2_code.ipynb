{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHMM:\n",
    "    \n",
    "    \"\"\" A class used to learn parameters of a Hidden Markov Model using Baum Welch algorithm \"\"\"\n",
    "    \n",
    "    def __init__(self, A, B, data, freeze_B): \n",
    "        \n",
    "        \"\"\" Instantiate a model instance with: \n",
    "        \n",
    "        A: (num_hidden*num_hidden) array representing transition probabilities between hidden states  \n",
    "        B: (num_hidden*num_obs) array representing emission probabilities conditioned on each hidden state \n",
    "        data: list of observations \n",
    "        freeze_B: list of Booleans of len=num_hidden indicating whether emission probabilities should be fixed \n",
    "            (e.g. [True, False, False] means to freeze only the first hidden state's)\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        # initialize HMM parameters \n",
    "        self.A = A \n",
    "        self.B = B\n",
    "        self.num_hidden, self.num_obs = B.shape\n",
    "        assert len(freeze_B) == self.num_hidden\n",
    "        self.freeze_B = freeze_B\n",
    "        \n",
    "        # initialize data parameters \n",
    "        self.data = data \n",
    "        self.T = len(data)\n",
    "        \n",
    "        # initialize additional attributes used in learning the parameters of an HMM \n",
    "        self.forwards = np.zeros((self.num_hidden, self.T))\n",
    "        self.backwards = np.zeros((self.num_hidden, self.T))\n",
    "        self.coefs = np.zeros(self.T) # coefs used to rescale forward/backward probas for numerical stability \n",
    "        self.gammas = np.zeros((self.num_hidden, self.T))\n",
    "        self.ixs = np.zeros((self.num_hidden, self.num_hidden, self.T-1))\n",
    "        \n",
    "    def forward_pass(self, pi):\n",
    "        \n",
    "        \"\"\" Implements the forward algorithm to compute forward probabilities \n",
    "        (note: to prevent numerical underflow probabilities are normalized with scaling factors 'coefs') \"\"\"\n",
    "        \n",
    "        # define initial probabilities pi if not provided \n",
    "        if pi is None: \n",
    "            if not np.any(self.gammas):\n",
    "                # use gammas at t=0 if estimates already exist \n",
    "                pi = self.gammas[:,0]\n",
    "            else:\n",
    "                # in case of cold start, assume all hidden states are equally probable \n",
    "                pi = np.full(shape=(self.num_hidden), fill_value=1./self.num_hidden)\n",
    "        \n",
    "        # compute first time step \n",
    "        self.forwards[:,0] = np.multiply(pi, self.B[:, self.data[0]-1]) # because 0-index \n",
    "        self.coefs[0] = 1 / self.forwards[:,0].sum()\n",
    "        self.forwards[:,0] = self.coefs[0] * self.forwards[:,0]\n",
    "\n",
    "        # iterate over rest of time steps \n",
    "        for t in range(1, self.T): \n",
    "            self.forwards[:,t] = np.multiply(self.A @ self.forwards[:,t-1], self.B[:, self.data[t]-1])\n",
    "            self.coefs[t] = 1 / self.forwards[:,t].sum()\n",
    "            self.forwards[:,t] = self.coefs[t] * self.forwards[:,t]\n",
    "            \n",
    "    def backward_pass(self): \n",
    "        \n",
    "        \"\"\" Implements backward algorithm to compute backward probabilities \n",
    "        (note: uses 'coefs' computed in forward step to normalize probabilities to prevent underflow) \"\"\"\n",
    "        \n",
    "        # compute last time step \n",
    "        self.backwards[:, -1] = 1\n",
    "        self.backwards[:, -1] = self.coefs[-1] * self.backwards[:, -1]\n",
    "\n",
    "        # iterate backward through rest of time steps \n",
    "        for t in reversed(range(self.T-1)):\n",
    "            self.backwards[:,t] = np.multiply(self.A @ self.backwards[:,t+1], self.B[:, self.data[t+1]-1])\n",
    "            self.backwards[:,t] = self.coefs[t] * self.backwards[:,t]\n",
    "            \n",
    "    def e_step(self, pi=None):\n",
    "        \n",
    "        \"\"\" Expectation step of the Baum-Welch EM algorithm. Uses forward and backward probabilities to compute: \n",
    "            - gammas: (num_hidden*T) array representing probabilities of being in a hidden state j at time t\n",
    "            - ixs: (num_hidden*num_hidden*T-1) array representing probabilities of transitioning \n",
    "            from hidden state i at time t to hidden state j at time t+1 \"\"\"\n",
    "        \n",
    "        self.forward_pass(pi)\n",
    "        self.backward_pass()\n",
    "        \n",
    "        # compute ixs \n",
    "        for t in range(self.T-1):\n",
    "            for i in range(self.num_hidden):\n",
    "                for j in range(self.num_hidden): \n",
    "                    self.ixs[i,j,t] = self.forwards[i,t] * self.A[i,j] * \\\n",
    "                        self.B[j, self.data[t+1]-1] * self.backwards[j,t+1]\n",
    "        \n",
    "        # compute gammas \n",
    "        for t in range(self.T):\n",
    "            self.gammas[:,t] = np.multiply(self.forwards[:,t], self.backwards[:,t])\n",
    "    \n",
    "    def m_step(self): \n",
    "\n",
    "        \"\"\" Maximization step of the Baum-Welch EM algorithm. Uses gammas and ixs to update \n",
    "        transition probabilities A and emission probabilities B. \"\"\"\n",
    "\n",
    "        # re-estimate A \n",
    "        for i in range(self.num_hidden):\n",
    "            for j in range(self.num_hidden):\n",
    "                self.A[i,j] = self.ixs[i,j,:].sum() / self.ixs[i,:,:].sum()        \n",
    "                \n",
    "        # re-estimate B \n",
    "        for j in range(self.num_hidden):\n",
    "            if self.freeze_B[j]: # if one die's proba is fixed don't update it \n",
    "                pass \n",
    "            else:\n",
    "                for k in range(self.num_obs):\n",
    "                    obs_mask = np.array([datum == k+1 for datum in self.data])\n",
    "                    self.B[j,k] = (self.gammas[j,:] * obs_mask).sum() / self.gammas[j,:].sum()\n",
    "                \n",
    "    def train(self, num_iter, initial_pi):\n",
    "        \n",
    "        \"\"\" Runs Baum-Welch algo for num_iter times to update model parameters, store parameters at each \n",
    "        time step to output for analysis \"\"\"\n",
    "        \n",
    "        # initialize dictionaries to hold params \n",
    "        transition_probs, emission_probs = {}, {} \n",
    "        \n",
    "        # run EM for num_iter iterations \n",
    "        for m in range(1, num_iter+1): \n",
    "            self.e_step(initial_pi) # fix initial_pi in this model because we know casino started w/ fair die\n",
    "            self.m_step() \n",
    "            transition_probs[m] = self.A.copy() \n",
    "            emission_probs[m] = self.B.copy() \n",
    "            \n",
    "        return transition_probs, emission_probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "with open(\"sequence.txt\", \"r\") as f:\n",
    "    data = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.03627642e-04 9.99396372e-01]\n",
      " [1.17489317e-03 9.98825107e-01]]\n",
      "[[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.26375721 0.14044373 0.13728886 0.13826394 0.13742637 0.18281989]]\n"
     ]
    }
   ],
   "source": [
    "# two dice\n",
    "A = np.array([[.5, .5], \n",
    "              [.5, .5]])\n",
    "B = np.array([[1./6, 1./6, 1./6, 1./6, 1./6, 1./6], \n",
    "              [1./6, 1./6, 1./6, 1./6, 1./6, 1./6]])\n",
    "initial_pi = np.array([1., 0.])\n",
    "freeze_B = [True, False]\n",
    "\n",
    "model_2d = ModelHMM(A, B, data, freeze_B)\n",
    "transition_probs_2d, emission_probs_2d = model_2d.train(num_iter=200, initial_pi=initial_pi)\n",
    "print(model_2d.A)\n",
    "print(model_2d.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.11682682e-03 1.13400838e-01 8.85482335e-01]\n",
      " [6.43397373e-04 6.86016827e-01 3.13339775e-01]\n",
      " [4.61215627e-03 2.25477124e-01 7.69910720e-01]]\n",
      "[[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.11264013 0.17308977 0.16759647 0.16054701 0.14047959 0.24564703]\n",
      " [0.32096227 0.12788196 0.12720243 0.13446415 0.15020126 0.13928793]]\n"
     ]
    }
   ],
   "source": [
    "# three dice - don't do this (need to break symmetry)\n",
    "A = np.array([[.34, .33, .33], \n",
    "              [.33, .34, .33],\n",
    "              [.33, .33, .34]])\n",
    "B = np.array([[1./6, 1./6, 1./6, 1./6, 1./6, 1./6], \n",
    "              [2./7, 1./7, 1./7, 1./7, 1./7, 1./7],\n",
    "              [1./7, 1./7, 1./7, 1./7, 1./7, 2./7]])\n",
    "initial_pi = np.array([1., 0., 0.])\n",
    "freeze_B = [True, False, False]\n",
    "\n",
    "model_3d = ModelHMM(A, B, data, freeze_B)\n",
    "transition_probs_3_dice, emission_probs_3d = model_3d.train(num_iter=200, initial_pi=initial_pi)\n",
    "print(model_3d.A)\n",
    "print(model_3d.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.52477813e-05 4.99957376e-01 4.99957376e-01]\n",
      " [5.93080158e-04 5.07161721e-01 4.92245199e-01]\n",
      " [5.93080158e-04 4.92245199e-01 5.07161721e-01]]\n",
      "[[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.26445784 0.14119105 0.13793066 0.13915996 0.13820468 0.17905582]\n",
      " [0.26445784 0.14119105 0.13793066 0.13915996 0.13820468 0.17905582]]\n"
     ]
    }
   ],
   "source": [
    "# three dice - don't do this (need to break symmetry)\n",
    "A = np.array([[.34, .33, .33], \n",
    "              [.33, .34, .33],\n",
    "              [.33, .33, .34]])\n",
    "B = np.array([[1./6, 1./6, 1./6, 1./6, 1./6, 1./6], \n",
    "              [1./6, 1./6, 1./6, 1./6, 1./6, 1./6],\n",
    "              [1./6, 1./6, 1./6, 1./6, 1./6, 1./6]])\n",
    "initial_pi = np.array([1., 0., 0.])\n",
    "freeze_B = [True, False, False]\n",
    "\n",
    "model_3d = ModelHMM(A, B, data, freeze_B)\n",
    "transition_probs_3_dice, emission_probs_3d = model_3d.train(num_iter=200, initial_pi=initial_pi)\n",
    "print(model_3d.A)\n",
    "print(model_3d.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series([(k,v[0,1]) for (k,v) in transition_probs_2d.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "fake_data1 = np.random.choice([1,1,1,1,1,2,3,4,5,6], size=2500)\n",
    "fake_data2 = np.random.choice([1,2,3,4,5,6], size=2500)\n",
    "fake_data = np.concatenate([fake_data1, fake_data2])\n",
    "random.shuffle(fake_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
