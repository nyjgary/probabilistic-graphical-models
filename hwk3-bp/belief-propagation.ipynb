{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 1005 Hwk 3 - Belief Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 - Sum-product algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import networkx as nx\n",
    "from fglib import graphs, nodes, rv, inference, utils\n",
    "from pyldpc import RegularH, CodingMatrixG # old version of API\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.3]\n",
      " [0.2 0.3]]\n",
      "(2, 2)\n",
      "[[[0.2]\n",
      "  [0.3]]\n",
      "\n",
      " [[0.2]\n",
      "  [0.3]]]\n",
      "(2, 2, 1)\n",
      "[[[0.2, 0.8], [0.25, 0.75]], [[0.7, 0.3], [0.3, 0.7]]]\n",
      "[[[0.04  0.16 ]\n",
      "  [0.075 0.225]]\n",
      "\n",
      " [[0.14  0.06 ]\n",
      "  [0.09  0.21 ]]]\n",
      "(2, 2, 2)\n",
      "[0.345 0.655]\n",
      "[[0.1725 0.1725]\n",
      " [0.4585 0.1965]]\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "dist_f3 = [0.5, 0.5]\n",
    "dist_f4 = [0.4,0.6]\n",
    "px3x4=np.outer(dist_f3,dist_f4)\n",
    "print(px3x4)\n",
    "print(px3x4.shape)\n",
    "px3x4=np.reshape(px3x4, np.shape(px3x4)+(1,))\n",
    "print(px3x4)\n",
    "print(px3x4.shape)\n",
    "px2_conditioned_x3x4=[[[0.2,0.8],\n",
    "                     [0.25,0.75],],\n",
    "                     [[0.7,0.3],\n",
    "                     [0.3,0.7]]]\n",
    "print(px2_conditioned_x3x4)\n",
    "dist_f234 =px3x4*px2_conditioned_x3x4\n",
    "print(dist_f234)\n",
    "print(dist_f234.shape)\n",
    "px2= np.sum(dist_f234, axis=(0,1))\n",
    "print(px2)\n",
    "px1_conditioned_x2 = [[0.5,0.5],\n",
    "                     [0.7,0.3]]\n",
    "dist_f12 =px2[:,np.newaxis]*px1_conditioned_x2\n",
    "print(dist_f12)\n",
    "print(dist_f12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_debug_graph():\n",
    "\n",
    "    # Create factor graph\n",
    "    fg = graphs.FactorGraph()\n",
    "\n",
    "    # Create variable nodes\n",
    "    x1 = nodes.VNode(\"x1\", rv.Discrete)\n",
    "    x2 = nodes.VNode(\"x2\", rv.Discrete)\n",
    "    x3 = nodes.VNode(\"x3\", rv.Discrete)\n",
    "    x4 = nodes.VNode(\"x4\", rv.Discrete)\n",
    "\n",
    "    # Create factor nodes\n",
    "    f12 = nodes.FNode(\"f12\")\n",
    "    f234 = nodes.FNode(\"f234\")\n",
    "    f3 = nodes.FNode(\"f3\")\n",
    "    f4 = nodes.FNode(\"f4\")\n",
    "\n",
    "    # Add nodes to factor graph\n",
    "    fg.set_nodes([x1, x2, x3, x4])\n",
    "    fg.set_nodes([f12, f234, f3,f4 ])\n",
    "\n",
    "    # Add edges to factor graph\n",
    "    fg.set_edge(x1, f12)\n",
    "    fg.set_edge(f12, x2)\n",
    "    fg.set_edge(x2, f234)\n",
    "    fg.set_edge(f234, x3)\n",
    "    fg.set_edge(f234, x4)\n",
    "    fg.set_edge(x3, f3)\n",
    "    fg.set_edge(x4, f4)\n",
    "\n",
    "    #add potential for f_3: p(x3)\n",
    "    dist_f3 = [0.5, 0.5]\n",
    "    f3.factor = rv.Discrete(dist_f3,x3)\n",
    "    \n",
    "    #add potential for f_4: p(x4)\n",
    "    dist_f4 = [0.4,0.6]\n",
    "    f4.factor = rv.Discrete(dist_f4,x4)\n",
    "    \n",
    "    # add potential for f_{234}: p(x2, x3, x4) = p(x2|x3,x4) p(x3,x4)\n",
    "    px3x4=np.outer(dist_f3,dist_f4)\n",
    "    px3x4=np.reshape(px3x4, np.shape(px3x4)+(1,))\n",
    "    px2_conditioned_x3x4=[[[0.2,0.8],\n",
    "                         [0.25,0.75],],\n",
    "                         [[0.7,0.3],\n",
    "                         [0.3,0.7]]]\n",
    "    \n",
    "    dist_f234 =px3x4*px2_conditioned_x3x4\n",
    "    f234.factor = rv.Discrete(dist_f234,x3,x4,x2)\n",
    "   \n",
    "    # add potential for f_{12}:  p (x1,x2) = p(x1 | x2) p(x2)\n",
    "    px1_conditioned_x2 = [[0.5,0.5],\n",
    "                         [0.7,0.3]]\n",
    "    px2= np.sum(dist_f234, axis=(0,1))\n",
    "    dist_f12 =px2[:,np.newaxis]*px1_conditioned_x2\n",
    "    f12.factor = rv.Discrete(dist_f12,x2,x1)\n",
    "    # Perform sum-product algorithm on factor graph\n",
    "    # and request belief of variable node x1\n",
    "    \n",
    "    belief = inference.sum_product(fg, x1)\n",
    "    print(belief)\n",
    "    return (fg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Implement sum-product algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beliefs_at_iter(beliefs_hist, iter_num):\n",
    "    \n",
    "    \"\"\" Retrieves beliefs at a given iteration. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    beliefs_hist: dict\n",
    "        A log of beliefs after each iteration of loopy belief propagation, represented by {k:v} where k is \n",
    "        iteration number and v is a nested dictionary representing beliefs at that iteration \n",
    "    iter_num: int\n",
    "        Iteration number at which to retrieve beliefs \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    beliefs_at_iter: dict \n",
    "        A dictionary of beliefs at iter_num {k1:v1}, where k1 is variable node and v1 is the node's beliefs,\n",
    "        represented by their probability mass functions \n",
    "    \"\"\"\n",
    "    \n",
    "    beliefs_at_iter = {}\n",
    "    for v in beliefs_hist: \n",
    "        beliefs_at_iter[v] = beliefs_hist[v][iter_num]\n",
    "    return beliefs_at_iter \n",
    "\n",
    "def get_beliefs(model, n_iter=10):\n",
    "    \n",
    "    \"\"\" Runs loopy belief propagation (sum-product) algorithm through a factor graph model \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: object \n",
    "        An instance of FactorGraph class in fglib library. \n",
    "    n_iter: int\n",
    "        Number of iterations to run loopy belief propagation \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    beliefs: dict    \n",
    "        A dictionary of beliefs after the last iteration of loopy belief propagation \n",
    "    \n",
    "    beliefs_hist: dict of dicts \n",
    "        A log of beliefs after each iteration of loopy belief propagation, represented by {k:v} where k is \n",
    "        iteration number and v is a nested dictionary representing beliefs at that iteration \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    beliefs_hist = {v:[] for v in model.get_vnodes()}\n",
    "    \n",
    "    # initialize variable to factor messages \n",
    "    for v in model.get_vnodes():\n",
    "        for f in v.neighbors():\n",
    "            initial_msg = rv.Discrete(np.ones(2,), v)\n",
    "            model[v][f]['object'].set_message(v, f, initial_msg.normalize())\n",
    "\n",
    "    # run parallel updates for n_iter times \n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        # update factor-to-variable messages\n",
    "        for f in model.get_fnodes():\n",
    "            for v in f.neighbors():\n",
    "                msg = f.factor \n",
    "                for n in f.neighbors(exclusion=v):\n",
    "                    msg *= model[n][f]['object'].get_message(n, f)\n",
    "                    msg = msg.normalize()\n",
    "                for n in f.neighbors(exclusion=v):\n",
    "                    msg = msg.marginalize(n, normalize=True)\n",
    "                model[f][v]['object'].set_message(f, v, msg.normalize())\n",
    "                \n",
    "        # update variable-to-factor messages \n",
    "        for v in model.get_vnodes(): \n",
    "            for f in v.neighbors():\n",
    "                msg = rv.Discrete(np.ones(2,), v)\n",
    "                for n in v.neighbors(exclusion=f):\n",
    "                    msg *= model[n][v]['object'].get_message(n, v)\n",
    "                    msg = msg.normalize()\n",
    "                model[v][f]['object'].set_message(v, f, msg.normalize())\n",
    "\n",
    "        # store beliefs of variable nodes \n",
    "        for v in model.get_vnodes():\n",
    "            belief = rv.Discrete(np.ones(2,), v)\n",
    "            for n in v.neighbors():\n",
    "                belief *= model[n][v]['object'].get_message(n, v)\n",
    "            beliefs_hist[v].append(belief.normalize())\n",
    "            \n",
    "    beliefs = get_beliefs_at_iter(beliefs_hist, n_iter-1)\n",
    "    \n",
    "    return beliefs, beliefs_hist\n",
    "\n",
    "def print_beliefs(beliefs):\n",
    "    \n",
    "    \"\"\" Print out beliefs at each variable node \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    beliefs: dict \n",
    "        A dictionary of beliefs represented by {k:v}, where k is a variable node and v its corresponding PMF  \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None. Prints out beliefs, one line per variable node.  \n",
    "    \"\"\"\n",
    "    \n",
    "    for (v,b) in beliefs.items():\n",
    "        print(v, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Test on 4-node factor graph provided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65897284 0.34102716]\n",
      "x1 [0.65897284 0.34102716]\n",
      "x2 [0.20513578 0.79486422]\n",
      "x3 [0.52640912 0.47359088]\n",
      "x4 [0.28679718 0.71320282]\n"
     ]
    }
   ],
   "source": [
    "fg = make_debug_graph()\n",
    "beliefs, _ = get_beliefs(fg)\n",
    "print_beliefs(beliefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - Low-Density Priority Check (LDPC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factor_potentials(d_v): # where d_v = num of variable nodes in parity check equation \n",
    "    \"\"\" Build N-dimensional factor potential to represent a parity check equation  \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_v: int \n",
    "        Number of dimensions in factor potential, aka # of variable nodes per partiy check equation \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    phi: np.array\n",
    "        N-dimentional factor potential representing the parity check equation. Indices of array represent possible\n",
    "        permutations of binary values {0,1} across dimensions, and phi=1 iff sum of indices is divisible by 2 \n",
    "        (i.e. passes parity check), and phi=0 otherwise (i.e. fails parity check)\n",
    "    \"\"\"\n",
    "    \n",
    "    permutations = product([0,1], repeat=d_v)\n",
    "    phi = np.zeros([2 for i in range(d_v)])\n",
    "    for idx in permutations:\n",
    "        if sum(idx) % 2 == 0: \n",
    "            phi[idx] = 1\n",
    "        else:\n",
    "            phi[idx] = 0\n",
    "    return phi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ldpc_fg(H):\n",
    "    \"\"\" Given an arbitrary parity check matrix create a corresponding factor graph \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    H: np.array\n",
    "        MxN parity check matrix where M = # of parity check equations and N = # of variable nodes \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fg: object \n",
    "        An instantiation of the FactorGraph class in fglib library, representing the LDPC graph that will \n",
    "        be used for decoding messages         \n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize factor graph  \n",
    "    fg = graphs.FactorGraph()\n",
    "    \n",
    "    # infer the number of factor and variable nodes required\n",
    "    num_factors, num_variables = H.shape\n",
    "\n",
    "    # create factor nodes \n",
    "    fnodes = [] \n",
    "    for i in range(num_factors):\n",
    "        fnodes.append(nodes.FNode(\"f\" + str(i)))\n",
    "    \n",
    "    # create variable nodes \n",
    "    vnodes = [] \n",
    "    for j in range(num_variables):\n",
    "        vnodes.append(nodes.VNode(\"x\" + str(j), rv.Discrete))\n",
    "        \n",
    "    # add nodes to factor graph \n",
    "    fg.set_nodes(vnodes)\n",
    "    fg.set_nodes(fnodes)\n",
    "    \n",
    "    # add edges to factor graph based on H \n",
    "    for i in range(num_factors):\n",
    "        for j in range(num_variables):\n",
    "            if H[i,j] == 1:\n",
    "                fg.set_edge(fnodes[i], vnodes[j])\n",
    "                \n",
    "    # set factor potentials \n",
    "    for fnode in fg.get_fnodes():\n",
    "        vnodes2check = [vnode for vnode in fnode.neighbors()]\n",
    "        fnode_potentials = get_factor_potentials(len(vnodes2check))\n",
    "        fnode.factor = rv.Discrete(fnode_potentials, *vnodes2check)\n",
    "        \n",
    "    return fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prob(model, codeword):\n",
    "    \"\"\" Evaluate the unnormalized probability of a given codeword under a LDPC graphical model \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: object\n",
    "        MxN parity check matrix where M = # of parity check equations and N = # of variable nodes \n",
    "    codeword: np.array\n",
    "        Message represented by an array of binary values to be evaluated\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    prob: float \n",
    "        Unnormalized probability of a given codeword under the LDPC graphical model \n",
    "        In our use case, this evaluates to 0 if the codeword fails parity checks, and 1 if it passes \n",
    "    \"\"\"\n",
    "    \n",
    "    prob = 1\n",
    "    for f in model.get_fnodes():\n",
    "        v_checked = [int(str(v)[1:]) for v in f.neighbors()]\n",
    "        idx = tuple([codeword[i] for i in v_checked])\n",
    "        prob *= f.factor.pmf[idx]\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 1]\n",
      " [1 0 1 1 1 0 0 0]\n",
      " [0 1 0 0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# create parity check matrix (note d_v = ones per column, d_c = ones per row)\n",
    "H = RegularH(n=8, d_v=2, d_c=4)\n",
    "print(H)\n",
    "ldpc_fg = make_ldpc_fg(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given H = [[1 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 1]\n",
      " [1 0 1 1 1 0 0 0]\n",
      " [0 1 0 0 0 1 1 1]], this code is expected to fail parity check: [1 0 0 0 0 0 0 0]\n",
      "Prob is 0.0\n"
     ]
    }
   ],
   "source": [
    "# define invalid codewords \n",
    "invalid_code = np.array([1, 0, 0, 0, 0, 0, 0, 0]) # should fail parity check \n",
    "print(\"Given H = {}, this code is expected to fail parity check: {}\".format(H, invalid_code))\n",
    "prob = evaluate_prob(ldpc_fg, invalid_code)\n",
    "print(\"Prob is {}\".format(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros should always pass parity check: [0 0 0 0 0 0 0 0]\n",
      "Prob is 1.0\n"
     ]
    }
   ],
   "source": [
    "# zero should pass \n",
    "valid_code = np.zeros(8, dtype=int)\n",
    "print(\"Zeros should always pass parity check: {}\".format(valid_code))\n",
    "prob = evaluate_prob(ldpc_fg, valid_code)\n",
    "print(\"Prob is {}\".format(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b: 128-bit LDPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unary_potential(obs, err):\n",
    "    \"\"\" Build unary potential of a variable node based on observed data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obs: int\n",
    "        Observed bit (either 0 or 1) at variable node of interest \n",
    "    err: float\n",
    "        Assumed error rate of the binary symmetric channel  \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    phi: np.array\n",
    "        Unary potential of the variable node, represented by an array of two values, which are the respective\n",
    "        probabilities that the node might take on value of 0 vs. 1, given the observation and error rate  \n",
    "    \"\"\"\n",
    "    \n",
    "    phi = np.zeros(shape=(2,))\n",
    "    phi[obs] = 1 - err \n",
    "    phi[1-obs] = err \n",
    "    return phi \n",
    "\n",
    "def set_unary_factors(fg, msg, err):\n",
    "    \"\"\" Adds unary factors to a LDPC factor graph \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fg: object\n",
    "        An instantiation of the FactorGraph class in fglib library, representing the LDPC graphical model \n",
    "        *before* unary factors are added \n",
    "    msg: np.array\n",
    "        Message received, represented by an array of binary values \n",
    "    err: float \n",
    "        Assumed error rate of the binary symmetric channel  \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fg: object \n",
    "        An instantiation of the FactorGraph class in fglib library, representing the LDPC graphical model \n",
    "        *after* unary factors are added \n",
    "    \"\"\"\n",
    "    \n",
    "    for vnode in fg.get_vnodes():\n",
    "        idx = int(str(vnode)[1:])\n",
    "        phi = get_unary_potential(msg[idx-1], err)\n",
    "        ufnode = nodes.FNode(\"u\" + str(idx))\n",
    "        ufnode.factor = rv.Discrete(phi, vnode)\n",
    "        fg.set_node(ufnode)\n",
    "        fg.set_edge(ufnode, vnode)\n",
    "    return fg\n",
    "\n",
    "# def transmit(original, err):\n",
    "#     is_flipped = np.random.rand(len(original)) < err\n",
    "#     transmitted = np.where(is_flipped, 1 - original, original)\n",
    "#     return transmitted\n",
    "\n",
    "def add_noise(original, err):\n",
    "    \"\"\" Adds noise to simulate output of a binary symmetric channel  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    original: np.array\n",
    "        Original message transmitted, represented by an array of binary bits  \n",
    "    err: float \n",
    "        Assumed error rate of the binary symmetric channel  \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    received: np.array \n",
    "        Message received as output of binary symmetric channel, i.e. after error was introduced \n",
    "    \"\"\"\n",
    "    \n",
    "    is_flipped = np.random.rand(len(original)) < err\n",
    "    received = np.where(is_flipped, 1 - original, original)\n",
    "    return received\n",
    "\n",
    "def decode_msg(beliefs):\n",
    "\n",
    "    \"\"\" Decodes message by setting each bit to the maximum of posterior marginal beliefs \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    beliefs: dict\n",
    "        A dictionary of beliefs represented by {k:v}, where k is a variable node and v its corresponding PMF  \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    decoded: np.array \n",
    "        Decoded message \n",
    "    \"\"\"\n",
    "    \n",
    "    decoded = np.zeros(len(beliefs))\n",
    "    for v in beliefs:\n",
    "        pos = int(str(v)[1:]) \n",
    "        decoded[pos] = np.asscalar(np.argmax(beliefs[v].pmf))\n",
    "    return decoded \n",
    "\n",
    "def hamming_dist(source, decoded):\n",
    "    \n",
    "    \"\"\" Computes hamming instance between the source message and decoded message \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    source: np.array\n",
    "        Source message, represented an array of binary bits \n",
    "    decoded: np.array\n",
    "        Decoded message, represented an array of binary bits          \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    hdist: int \n",
    "        Hamming distance between source and decoded messages, defined as number of differing bits \n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sum(source != decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(source, err, n_iter, d_v=4, d_c=8):\n",
    "    \n",
    "    \"\"\" Simulate transmission of a source message through a binary symmetric channel then \n",
    "        run loopy belief propagation to decode the received message \n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    source: np.array\n",
    "        Source message, represented an array of binary bits \n",
    "    err: float \n",
    "        Assumed error rate of the binary symmetric channel  \n",
    "    n_iter: int\n",
    "        Number of iterations to run loopy belief propagation \n",
    "    d_v: int (default 4)\n",
    "        Number of variable nodes checked in each parity check equation \n",
    "    d_c: int (default 8)\n",
    "        Number of parity check equations \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    hdist: int \n",
    "        Hamming distance between source and decoded messages, defined as number of differing bits \n",
    "    beliefs: dict    \n",
    "        A dictionary of beliefs after the last iteration of loopy belief propagation \n",
    "    beliefs_hist: dict of dicts \n",
    "        A log of beliefs after each iteration of loopy belief propagation, represented by {k:v} where k is \n",
    "        iteration number and v is a nested dictionary representing beliefs at that iteration \n",
    "    decoded: np.array\n",
    "        Decoded message, represented an array of binary bits          \n",
    "    \"\"\"\n",
    "    \n",
    "    # add noise to msg transmitted \n",
    "    received = add_noise(source, err)\n",
    "    \n",
    "    # create factor graph model used to decode message (SHOULD THIS BE REFACTORED?)\n",
    "    len_msg = len(source)\n",
    "    H = RegularH(len_msg, d_v, d_c)\n",
    "    ldpc_fg = make_ldpc_fg(H)\n",
    "    ldpc_fg = set_unary_factors(ldpc_fg, received, err)\n",
    "    \n",
    "    # run loopy belief propagation \n",
    "    beliefs, beliefs_history = get_beliefs(ldpc_fg, n_iter)\n",
    "    \n",
    "    # decode message and compute distance \n",
    "    decoded = decode_msg(beliefs)\n",
    "    hdist = hamming_dist(source, decoded)\n",
    "    \n",
    "    return hdist, beliefs, beliefs_history, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = np.zeros(256, dtype=int)\n",
    "hdist, beliefs, beliefs_history, decoded = run_experiment(source, .05, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_at_iter(beliefs, original, iter_num):\n",
    "    beliefs_at_iter = get_beliefs_at_iter(beliefs_history, iter_num)\n",
    "    decoded = decode_msg(beliefs_at_iter)\n",
    "    hdist = hamming_dist(original, decoded)\n",
    "    return hdist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, err, n_trials):\n",
    "    pd.DataFrame(results).T.plot(figsize=(14,5), legend=None)\n",
    "    plt.ylabel('Hamming distance')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.title('Hamming distance versus iteration with err={} for {} random trials'.format(err, n_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(err, n_trials, n_iter=50, msg_len=256, d_v=4, d_c=8):\n",
    "    \n",
    "    results = []  \n",
    "    \n",
    "    for trial_num in range(n_trials):\n",
    "        _, _, beliefs_history, _, original = run_experiment(err, msg_len, n_iter, d_v, d_c) \n",
    "        \n",
    "        result = {} \n",
    "        for i in range(n_iter):\n",
    "            beliefs_at_iter = get_beliefs_at_iter(beliefs_history, i)\n",
    "            decoded = decode_msg(beliefs_at_iter)\n",
    "            result[i+1] = hamming_dist(original, decoded)\n",
    "        results.append(result)\n",
    "        \n",
    "    plot_results(results, err, n_trials)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_experiments(err=0.05, n_trials=10, n_iter=50, msg_len=256, d_v=4, d_c=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_err8 = run_experiments(err=0.08, n_trials=10, n_iter=50, msg_len=256, d_v=4, d_c=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_err10 = run_experiments(err=0.10, n_trials=10, n_iter=50, msg_len=256, d_v=4, d_c=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from latest version of the library \n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "from scipy.sparse import csr_matrix\n",
    "pi = math.pi\n",
    "\n",
    "\n",
    "def int2bitarray(N, k):\n",
    "    \"\"\"\n",
    "    Changes array's base from int (base 10) to binary (base 2)\n",
    "    Parameters:\n",
    "    ===========\n",
    "    N: int N\n",
    "    k: Width of the binary array you would like to change N into.\n",
    "    N must not be greater than 2^k - 1.\n",
    "    >> Examples: int2bitarray(6,3) returns [1, 1, 0]\n",
    "                 int2bitarray(6,5) returns [0, 0, 1, 1,0]\n",
    "                 int2bitarray(255,8) returns [1, 1, 1, 1, 1, 1, 1, 1]\n",
    "                 int2bitarray(255,10) returns [0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    binary_string = bin(N)\n",
    "    length = len(binary_string)\n",
    "    bitarray = np.zeros(k, 'int')\n",
    "    for i in range(length-2):\n",
    "        bitarray[k-i-1] = int(binary_string[length-i-1])\n",
    "\n",
    "    return bitarray\n",
    "\n",
    "\n",
    "def bitarray2int(bitarray):\n",
    "\n",
    "    \"\"\" Changes array's base from binary (base 2) to int (base 10).\n",
    "    Parameters:\n",
    "    ===========\n",
    "    bitarray: Binary Array.\n",
    "    >> Examples: bitarray2int([1, 1, 0]) returns 6\n",
    "                 bitarray2int([0, 0, 1, 1,0]) returns 6\n",
    "                 bitarray2int([1, 1, 1, 1, 1, 1, 1, 1]) returns 255\n",
    "    \"\"\"\n",
    "\n",
    "    bitstring = \"\".join([str(i) for i in bitarray])\n",
    "\n",
    "    return int(bitstring, 2)\n",
    "\n",
    "\n",
    "def binaryproduct(X, Y):\n",
    "\n",
    "    \"\"\" Binary Matrices or Matrix-vector product in Z/2Z.\n",
    "    Works with scipy.sparse.csr_matrix matrices X, Y too.\"\"\"\n",
    "\n",
    "    A = X.dot(Y)\n",
    "\n",
    "    if type(A) != scipy.sparse.csr_matrix:\n",
    "        return A % 2\n",
    "\n",
    "    return A.toarray() % 2\n",
    "\n",
    "\n",
    "def gaussjordan(X, change=0):\n",
    "\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Performs the row reduced echelon form of X and returns it.\n",
    "    If change = 1, all changes in the X's rows are applied to\n",
    "    identity matrix P:\n",
    "    Let A be our parameter X. refA the reduced echelon form of A.\n",
    "    P is the square invertible matrix:\n",
    "    P.A = Aref.\n",
    "    -------------------------------------------------\n",
    "    Parameters:\n",
    "    X: 2D-Array.\n",
    "    change : boolean (default = 0)\n",
    "    ------------------------------------------------\n",
    "    change = 0  (default)\n",
    "     >>> Returns 2D-Array Row Reduced Echelon form of Matrix\n",
    "    change = 1\n",
    "    >>> Returns Tuple of 2D-arrays (refX, P) where P is described above.\n",
    "    \"\"\"\n",
    "\n",
    "    A = np.copy(X)\n",
    "    m, n = A.shape\n",
    "\n",
    "    if change:\n",
    "        P = np.identity(m).astype(int)\n",
    "\n",
    "    pivot_old = -1\n",
    "    for j in range(n):\n",
    "        filtre_down = A[pivot_old+1:m, j]\n",
    "        pivot = np.argmax(filtre_down)+pivot_old+1\n",
    "\n",
    "        if A[pivot, j]:\n",
    "            pivot_old += 1\n",
    "            if pivot_old != pivot:\n",
    "                aux = np.copy(A[pivot, :])\n",
    "                A[pivot, :] = A[pivot_old, :]\n",
    "                A[pivot_old, :] = aux\n",
    "                if change:\n",
    "                    aux = np.copy(P[pivot, :])\n",
    "                    P[pivot, :] = P[pivot_old, :]\n",
    "                    P[pivot_old, :] = aux\n",
    "\n",
    "            for i in range(m):\n",
    "                if i != pivot_old and A[i, j]:\n",
    "                    if change:\n",
    "                        P[i, :] = abs(P[i, :]-P[pivot_old, :])\n",
    "                    A[i, :] = abs(A[i, :]-A[pivot_old, :])\n",
    "\n",
    "        if pivot_old == m-1:\n",
    "            break\n",
    "\n",
    "    if change:\n",
    "        return A, P\n",
    "    return A\n",
    "\n",
    "\n",
    "def binaryrank(X):\n",
    "    \"\"\" Computes rank of a binary Matrix using Gauss-Jordan algorithm\"\"\"\n",
    "    A = np.copy(X)\n",
    "    m, n = A.shape\n",
    "\n",
    "    A = gaussjordan(A)\n",
    "\n",
    "    return sum([a.any() for a in A])\n",
    "\n",
    "\n",
    "def f1(y, sigma):\n",
    "    \"\"\" Normal Density N(1,sigma) \"\"\"\n",
    "    f = norm.pdf(y, loc=1, scale=sigma)\n",
    "    return f\n",
    "\n",
    "\n",
    "def fm1(y, sigma):\n",
    "    \"\"\" Normal Density N(-1,sigma) \"\"\"\n",
    "\n",
    "    f = norm.pdf(y, loc=-1, scale=sigma)\n",
    "    return f\n",
    "\n",
    "\n",
    "def bits2i(H, i):\n",
    "    \"\"\"\n",
    "    Computes list of elements of N(i)-j:\n",
    "    List of variables (bits) connected to Parity node i.\n",
    "    \"\"\"\n",
    "    if type(H) != scipy.sparse.csr_matrix:\n",
    "        m, n = H.shape\n",
    "        return list(np.where(H[i])[0])\n",
    "\n",
    "    indj = H.indptr\n",
    "    indi = H.indices\n",
    "\n",
    "    return [indi[a] for a in range(indj[i], indj[i+1])]\n",
    "\n",
    "\n",
    "def nodes2j(H, j):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes list of elements of M(j):\n",
    "    List of nodes (PC equations) connecting variable j.\n",
    "    \"\"\"\n",
    "\n",
    "    return bits2i(H.T, j)\n",
    "\n",
    "\n",
    "def bitsandnodes(H):\n",
    "\n",
    "    m, n = H.shape\n",
    "\n",
    "    bits = [bits2i(H, i) for i in range(m)]\n",
    "    nodes = [nodes2j(H, j)for j in range(n)]\n",
    "\n",
    "    return bits, nodes\n",
    "\n",
    "\n",
    "def incode(H, x):\n",
    "\n",
    "    \"\"\" Computes Binary Product of H and x. If product is null, x is in the code.\n",
    "        Returns appartenance boolean.\n",
    "    \"\"\"\n",
    "\n",
    "    return (binaryproduct(H, x) == 0).all()\n",
    "\n",
    "\n",
    "def gausselimination(A, b):\n",
    "\n",
    "    \"\"\" Applies Gauss Elimination Algorithm to X in order to solve a\n",
    "    linear system X.X = B. X is transformed to row echelon form:\n",
    "         |1 * * * * * |\n",
    "         |0 1 * * * * |\n",
    "         |0 0 1 * * * |\n",
    "         |0 0 0 1 * * |\n",
    "         |0 0 0 0 1 * |\n",
    "         |0 0 0 0 0 1 |\n",
    "         |0 0 0 0 0 0 |\n",
    "         |0 0 0 0 0 0 |\n",
    "         |0 0 0 0 0 0 |\n",
    "    Same row operations are applied on 1-D Array vector B.\n",
    "    Both arguments are sent back.\n",
    "    --------------------------------------\n",
    "    Parameters:\n",
    "    X: 2D-array.\n",
    "    B:      1D-array. Size must equal number of rows of X.\n",
    "    -----------------------------------\n",
    "    Returns:\n",
    "    Modified arguments X, B as described above.\n",
    "         \"\"\"\n",
    "    if type(A) == scipy.sparse.csr_matrix:\n",
    "        A = A.toarray().copy()\n",
    "    else:\n",
    "        A = A.copy()\n",
    "    b = b.copy()\n",
    "    n, k = A.shape\n",
    "\n",
    "    for j in range(min(k, n)):\n",
    "        listedepivots = [i for i in range(j, n) if A[i, j]]\n",
    "        if len(listedepivots):\n",
    "            pivot = np.min(listedepivots)\n",
    "        else:\n",
    "            continue\n",
    "        if pivot != j:\n",
    "            aux = (A[j, :]).copy()\n",
    "            A[j, :] = A[pivot, :]\n",
    "            A[pivot, :] = aux\n",
    "\n",
    "            aux = b[j].copy()\n",
    "            b[j] = b[pivot]\n",
    "            b[pivot] = aux\n",
    "\n",
    "        for i in range(j+1, n):\n",
    "            if A[i, j]:\n",
    "                A[i, :] = abs(A[i, :]-A[j, :])\n",
    "                b[i] = abs(b[i]-b[j])\n",
    "\n",
    "    return A, b\n",
    "\n",
    "def coding_matrix_systematic(X, sparse=True):\n",
    "\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Solves H.G' = 0 and finds the coding matrix G in the systematic form :\n",
    "    [I_k  A] by applying permutations on X.\n",
    "    CAUTION: RETURNS TUPLE (Hp,tGS) WHERE Hp IS A MODIFIED VERSION OF THE\n",
    "    GIVEN PARITY CHECK X, tGS THE TRANSPOSED\n",
    "    SYSTEMATIC CODING X ASSOCIATED TO Hp. YOU MUST USE THE RETURNED TUPLE\n",
    "    IN CODING AND DECODING, RATHER THAN THE UNCHANGED\n",
    "    PARITY-CHECK X H.\n",
    "    -------------------------------------------------\n",
    "    Parameters:\n",
    "    X: 2D-Array. Parity-check matrix.\n",
    "    sparse: (optional, default True): use scipy.sparse matrices\n",
    "    to speed up computation if n>100.\n",
    "    ------------------------------------------------\n",
    "    >>> Returns Tuple of 2D-arrays (Hp,GS):\n",
    "        Hp: Modified H: permutation of columns (The code doesn't change)\n",
    "        tGS: Transposed Systematic Coding matrix associated to Hp.\n",
    "    \"\"\"\n",
    "\n",
    "    H = X.copy()\n",
    "    m, n = H.shape\n",
    "\n",
    "    if n > 100 and sparse:\n",
    "        sparse = True\n",
    "    else:\n",
    "        sparse = False\n",
    "\n",
    "    P1 = np.identity(n, dtype=int)\n",
    "\n",
    "    Hrowreduced = gaussjordan(H)\n",
    "\n",
    "    k = n - sum([a.any() for a in Hrowreduced])\n",
    "\n",
    "    # After this loop, Hrowreduced will have the form H_ss : | I_(n-k)  A |\n",
    "\n",
    "    while(True):\n",
    "        zeros = [i for i in range(min(m, n)) if not Hrowreduced[i, i]]\n",
    "        indice_colonne_a = min(zeros)\n",
    "        list_ones = [j for j in range(indice_colonne_a+1, n)\n",
    "                     if Hrowreduced[indice_colonne_a, j]]\n",
    "        if not len(list_ones):\n",
    "            break\n",
    "\n",
    "        indice_colonne_b = min(list_ones)\n",
    "\n",
    "        aux = Hrowreduced[:, indice_colonne_a].copy()\n",
    "        Hrowreduced[:, indice_colonne_a] = Hrowreduced[:, indice_colonne_b]\n",
    "        Hrowreduced[:, indice_colonne_b] = aux\n",
    "\n",
    "        aux = P1[:, indice_colonne_a].copy()\n",
    "        P1[:, indice_colonne_a] = P1[:, indice_colonne_b]\n",
    "        P1[:, indice_colonne_b] = aux\n",
    "\n",
    "    # NOW, Hrowreduced has the form: | I_(n-k)  A | ,\n",
    "    # the permutation above makes it look like :\n",
    "    # |A  I_(n-k)|\n",
    "\n",
    "    P1 = P1.T\n",
    "    identity = list(range(n))\n",
    "    sigma = identity[n-k:] + identity[:n-k]\n",
    "\n",
    "    P2 = np.zeros(shape=(n, n), dtype=int)\n",
    "    P2[identity, sigma] = np.ones(n)\n",
    "\n",
    "    if sparse:\n",
    "        P1 = csr_matrix(P1)\n",
    "        P2 = csr_matrix(P2)\n",
    "        H = csr_matrix(H)\n",
    "\n",
    "    P = binaryproduct(P2, P1)\n",
    "\n",
    "    if sparse:\n",
    "        P = csr_matrix(P)\n",
    "\n",
    "    Hp = binaryproduct(H, np.transpose(P))\n",
    "\n",
    "    GS = np.zeros((k, n), dtype=int)\n",
    "    GS[:, :k] = np.identity(k)\n",
    "    GS[:, k:] = (Hrowreduced[:n-k, n-k:]).T\n",
    "\n",
    "    return Hp, GS.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_filepath):\n",
    "    img = cv2.imread(img_filepath,2)\n",
    "    img = cv2.resize(img, (40, 40))\n",
    "    ret, bw_img = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "    img_code = (bw_img / 255).astype(int)\n",
    "    img_code_flattened = img_code.flatten()\n",
    "    return img_code_flattened \n",
    "\n",
    "def show_image(binary_code):\n",
    "    code_reshaped = binary_code.reshape((40,40))\n",
    "    plt.imshow(code_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image('binary-image.png')\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H_ = RegularH(n=256, d_v=64, d_c=128)\n",
    "H_ = RegularH(n=3200, d_v=4, d_c=8)\n",
    "H, Gt = coding_matrix_systematic(H_)\n",
    "print(\"Shape of H: {}\".format(H.shape))\n",
    "print(\"Shape of Gt: {}\".format(Gt.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of img: {}\".format(img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_padded = np.concatenate([img, np.zeros(3)])\n",
    "print(\"Shape of img padded: {}\".format(img_padded.shape))\n",
    "t = Gt @ img_padded\n",
    "print(\"Shape of t: {}\".format(t.shape))\n",
    "r = add_noise(t, .05)\n",
    "print(\"Shape of r: {}\".format(r.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(r[:1600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_img(img):\n",
    "    H_ = RegularH(n=3200, d_v=4, d_c=8)\n",
    "    H, Gt = coding_matrix_systematic(H_)\n",
    "    img_padded = np.concatenate([img, np.zeros(3)])\n",
    "    t = Gt @ img_padded\n",
    "    return t, H, Gt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, H, Gt = encode_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(t[:1600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('binary-image.png',2)\n",
    "# img = cv2.resize(img, (40, 40))\n",
    "# ret, bw_img = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "# #cv2.imshow(\"Binary Image\",bw_img)\n",
    "# plt.imshow(bw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_code = (bw_img / 255).astype(int)\n",
    "# img_code_flattened = img_code.flatten()\n",
    "# img_code_transmitted = transmit(img_code_flattened, err=0.05)\n",
    "# transmitted_reshaped = img_code_transmitted.reshape(img_code.shape)\n",
    "# plt.imshow(transmitted_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H2 = RegularH(n=256, d_v=64, d_c=128)\n",
    "H3 = RegularH(n=8, d_v=2, d_c=4)\n",
    "print(H3.shape)\n",
    "print(H3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G3 = CodingMatrixG(H3)\n",
    "print(G3.shape)\n",
    "print(G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, Gt = coding_matrix_systematic(H3)\n",
    "print(H.shape)\n",
    "print(H)\n",
    "print(Gt.shape)\n",
    "print(Gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.array([1, 1, 1, 1, 0])\n",
    "print(s.shape)\n",
    "t = Gt @ s\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldpc_fg2 = make_ldpc_fg(H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 - Messsage passing on a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.pdf(50, loc=50, scale=np.sqrt(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.pdf(50, loc=60, scale=np.sqrt(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.pdf(60, loc=50, scale=np.sqrt(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.pdf(60, loc=60, scale=np.sqrt(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # numerically unstable \n",
    "\n",
    "# def get_beliefs(model, n_iter=10):\n",
    "    \n",
    "#     # initialize variable to factor messages \n",
    "#     for v in model.get_vnodes():\n",
    "#         for f in v.neighbors():\n",
    "#             initial_msg = rv.Discrete(np.ones(2,), v)\n",
    "#             model[v][f]['object'].set_message(v, f, initial_msg)\n",
    "\n",
    "#     # run parallel updates for n_iter times \n",
    "#     for i in range(n_iter):\n",
    "        \n",
    "#         # update factor-to-variable messages\n",
    "#         for f in model.get_fnodes():\n",
    "#             for v in f.neighbors():\n",
    "#                 msg = f.factor \n",
    "#                 for n in f.neighbors(exclusion=v):\n",
    "#                     msg *= model[n][f]['object'].get_message(n, f)\n",
    "#                 for n in f.neighbors(exclusion=v):\n",
    "#                     msg = msg.marginalize(n, normalize=False)\n",
    "#                 model[f][v]['object'].set_message(f, v, msg)\n",
    "                \n",
    "#         # update variable-to-factor messages \n",
    "#         for v in model.get_vnodes(): \n",
    "#             for f in v.neighbors():\n",
    "#                 msg = rv.Discrete(np.ones(2,), v)\n",
    "#                 for n in v.neighbors(exclusion=f):\n",
    "#                     msg *= model[n][v]['object'].get_message(n, v)\n",
    "#                 model[v][f]['object'].set_message(v, f, msg)\n",
    "\n",
    "#         # store beliefs of variable nodes \n",
    "#         beliefs = {}\n",
    "#         for v in model.get_vnodes():\n",
    "#             beliefs[v] = v.belief(model)\n",
    "    \n",
    "#     return beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_beliefs(model, n_iter=10):\n",
    "    \n",
    "#     # initialize variable to factor messages \n",
    "#     for v in model.get_vnodes():\n",
    "#         for f in v.neighbors():\n",
    "#             initial_msg = rv.Discrete(np.ones(2,), v)\n",
    "#             model[v][f]['object'].set_message(v, f, initial_msg.normalize())\n",
    "\n",
    "#     # run parallel updates for n_iter times \n",
    "#     for i in range(n_iter):\n",
    "        \n",
    "#         # update factor-to-variable messages\n",
    "#         for f in model.get_fnodes():\n",
    "#             for v in f.neighbors():\n",
    "#                 msg = f.factor \n",
    "#                 for n in f.neighbors(exclusion=v):\n",
    "#                     msg *= model[n][f]['object'].get_message(n, f)\n",
    "#                     msg = msg.normalize()\n",
    "#                 for n in f.neighbors(exclusion=v):\n",
    "#                     msg = msg.marginalize(n, normalize=True)\n",
    "#                 model[f][v]['object'].set_message(f, v, msg.normalize())\n",
    "                \n",
    "#         # update variable-to-factor messages \n",
    "#         for v in model.get_vnodes(): \n",
    "#             for f in v.neighbors():\n",
    "#                 msg = rv.Discrete(np.ones(2,), v)\n",
    "#                 for n in v.neighbors(exclusion=f):\n",
    "#                     msg *= model[n][v]['object'].get_message(n, v)\n",
    "#                     msg = msg.normalize()\n",
    "#                 model[v][f]['object'].set_message(v, f, msg.normalize())\n",
    "\n",
    "#         # store beliefs of variable nodes \n",
    "#         beliefs = {}\n",
    "#         for v in model.get_vnodes():\n",
    "#             belief = rv.Discrete(np.ones(2,), v)\n",
    "#             for n in v.neighbors():\n",
    "#                 belief *= model[n][v]['object'].get_message(n, v)\n",
    "#             beliefs[v] = belief.normalize()\n",
    "    \n",
    "#     return beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # attempt to take log, but answers don't seem correct\n",
    "\n",
    "# def get_beliefs_log(model, n_iter=10):\n",
    "    \n",
    "#     # initialize variable to factor messages \n",
    "#     for v in model.get_vnodes():\n",
    "#         for f in v.neighbors():\n",
    "#             initial_msg = rv.Discrete(np.ones(2,), v).normalize().log()\n",
    "#             model[v][f]['object'].set_message(v, f, initial_msg, logarithmic=True)\n",
    "\n",
    "#     # run parallel updates for n_iter times \n",
    "#     for i in range(n_iter):\n",
    "        \n",
    "#         # update factor-to-variable messages\n",
    "#         for f in model.get_fnodes():\n",
    "#             for v in f.neighbors():\n",
    "#                 sum_lambdas = rv.Discrete(np.zeros(2,), v)\n",
    "#                 for n in f.neighbors(exclusion=v):\n",
    "#                     sum_lambdas += model[n][f]['object'].get_message(n, f)\n",
    "#                 max_lambda = max(np.nan_to_num(sum_lambdas.pmf.flatten()))\n",
    "#                 sum_lambdas = rv.Discrete(sum_lambdas.pmf - max_lambda, v)\n",
    "#                 msg = rv.Discrete(np.exp(sum_lambdas.pmf), *sum_lambdas.dim)\n",
    "#                 msg = f.factor * msg\n",
    "#                 for n in f.neighbors(exclusion=v):\n",
    "#                     msg = msg.marginalize(n, normalize=False)\n",
    "#                 msg = msg.log()\n",
    "#                 msg = rv.Discrete(msg.pmf + max_lambda, v)\n",
    "#                 msg = msg.normalize()\n",
    "#                 model[f][v]['object'].set_message(f, v, msg, logarithmic=True)\n",
    "                \n",
    "#         # update variable-to-factor messages \n",
    "#         for v in model.get_vnodes(): \n",
    "#             for f in v.neighbors():\n",
    "#                 msg = rv.Discrete(np.zeros(2,), v)\n",
    "#                 for n in v.neighbors(exclusion=f):\n",
    "#                     msg += model[n][v]['object'].get_message(n, v)\n",
    "#                 model[v][f]['object'].set_message(v, f, msg, logarithmic=True)\n",
    "\n",
    "#         # store beliefs of variable nodes \n",
    "#         beliefs = {}\n",
    "#         for v in model.get_vnodes():\n",
    "#             log_b = v.belief(normalize=False)\n",
    "#             b = rv.Discrete(np.exp(log_b.pmf), log_b.dim).normalize()\n",
    "#             beliefs[v] = b\n",
    "    \n",
    "#     return beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
